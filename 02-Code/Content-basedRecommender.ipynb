{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 1.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
      "     ---------------------------------------- 7.1/7.1 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.0.1-cp39-cp39-win_amd64.whl (172.4 MB)\n",
      "     -------------------------------------- 172.4/172.4 MB 2.9 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp39-cp39-win_amd64.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sentence_transformers) (1.9.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sentence_transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-win_amd64.whl (977 kB)\n",
      "     -------------------------------------- 977.6/977.6 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "     -------------------------------------- 224.5/224.5 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2022.7.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.3.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\emad\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\emad\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (2.8.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\emad\\anaconda3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp39-cp39-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 3.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\emad\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\emad\\anaconda3\\lib\\site-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from torchvision->sentence_transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.11)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\emad\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py): started\n",
      "  Building wheel for sentence_transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=cdce3d2d9ddbcdb5c53d0f23075bbddd0132925473f0169ffe872f6d6b6b139d\n",
      "  Stored in directory: c:\\users\\emad\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, huggingface-hub, transformers, torchvision, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.14.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.29.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('movies.csv')\n",
    "X = np.array(data.genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492845018934406b972d74e4aeae53cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)925a9/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6404bebfbd2d4c6e9aeb937913e9f3c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a340e8687034466990b2dc368287f00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1a515925a9/README.md:   0%|          | 0.00/3.99k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a49c6b2913848489307d70bd22899df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)515925a9/config.json:   0%|          | 0.00/550 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a30db6968f94fe18e338f9397a4a502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2160fe9c5747778fb3b4d36e92eca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acde522ff2b42c1853588a6dca1fe83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1eb3a68bf346bda1b5d648fe0aef01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9e4c00d6f04501b25683583f89c223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)925a9/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de11a4a24c7040238f214b70caba5a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2700aa40d2346f9933a756a232229ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)1a515925a9/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aaaca97a5574244bad057d8596dab85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)15925a9/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f76439f0e5434e83598cd8a760e4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_data = X\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(text_data, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_data = pd.DataFrame(cosine_similarity(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3873</th>\n",
       "      <th>3874</th>\n",
       "      <th>3875</th>\n",
       "      <th>3876</th>\n",
       "      <th>3877</th>\n",
       "      <th>3878</th>\n",
       "      <th>3879</th>\n",
       "      <th>3880</th>\n",
       "      <th>3881</th>\n",
       "      <th>3882</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742909</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.670118</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.204250</td>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.681334</td>\n",
       "      <td>0.288585</td>\n",
       "      <td>0.231479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.670118</td>\n",
       "      <td>0.379071</td>\n",
       "      <td>0.179057</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.386236</td>\n",
       "      <td>0.288858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.742909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.502862</td>\n",
       "      <td>0.562338</td>\n",
       "      <td>0.309671</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.914236</td>\n",
       "      <td>0.445192</td>\n",
       "      <td>0.423351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562338</td>\n",
       "      <td>0.502862</td>\n",
       "      <td>0.354828</td>\n",
       "      <td>0.302125</td>\n",
       "      <td>0.520379</td>\n",
       "      <td>0.562338</td>\n",
       "      <td>0.462271</td>\n",
       "      <td>0.462271</td>\n",
       "      <td>0.462271</td>\n",
       "      <td>0.401916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.608846</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.449341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528796</td>\n",
       "      <td>0.433554</td>\n",
       "      <td>0.520940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.412435</td>\n",
       "      <td>0.481852</td>\n",
       "      <td>0.569144</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.560217</td>\n",
       "      <td>0.560217</td>\n",
       "      <td>0.560217</td>\n",
       "      <td>0.578279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.670118</td>\n",
       "      <td>0.502862</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>0.492471</td>\n",
       "      <td>0.881119</td>\n",
       "      <td>0.512211</td>\n",
       "      <td>0.516248</td>\n",
       "      <td>0.541614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401684</td>\n",
       "      <td>0.516617</td>\n",
       "      <td>0.643770</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>0.715911</td>\n",
       "      <td>0.715911</td>\n",
       "      <td>0.715911</td>\n",
       "      <td>0.671183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.562338</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360938</td>\n",
       "      <td>0.833884</td>\n",
       "      <td>0.639367</td>\n",
       "      <td>0.652417</td>\n",
       "      <td>0.454946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.930465</td>\n",
       "      <td>0.392453</td>\n",
       "      <td>0.386235</td>\n",
       "      <td>0.664495</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755545</td>\n",
       "      <td>0.755545</td>\n",
       "      <td>0.755545</td>\n",
       "      <td>0.547478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3883 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  1.000000  0.742909  0.608846  0.670118  0.676182  0.204250  0.608846   \n",
       "1  0.742909  1.000000  0.538996  0.502862  0.562338  0.309671  0.538996   \n",
       "2  0.608846  0.538996  1.000000  0.881119  0.833884  0.449341  1.000000   \n",
       "3  0.670118  0.502862  0.881119  1.000000  0.930465  0.492471  0.881119   \n",
       "4  0.676182  0.562338  0.833884  0.930465  1.000000  0.360938  0.833884   \n",
       "\n",
       "       7         8         9     ...      3873      3874      3875      3876  \\\n",
       "0  0.681334  0.288585  0.231479  ...  0.676182  0.670118  0.379071  0.179057   \n",
       "1  0.914236  0.445192  0.423351  ...  0.562338  0.502862  0.354828  0.302125   \n",
       "2  0.528796  0.433554  0.520940  ...  0.833884  0.881119  0.412435  0.481852   \n",
       "3  0.512211  0.516248  0.541614  ...  0.930465  1.000000  0.401684  0.516617   \n",
       "4  0.639367  0.652417  0.454946  ...  1.000000  0.930465  0.392453  0.386235   \n",
       "\n",
       "       3877      3878      3879      3880      3881      3882  \n",
       "0  0.350133  0.676182  0.386236  0.386236  0.386236  0.288858  \n",
       "1  0.520379  0.562338  0.462271  0.462271  0.462271  0.401916  \n",
       "2  0.569144  0.833884  0.560217  0.560217  0.560217  0.578279  \n",
       "3  0.643770  0.930465  0.715911  0.715911  0.715911  0.671183  \n",
       "4  0.664495  1.000000  0.755545  0.755545  0.755545  0.547478  \n",
       "\n",
       "[5 rows x 3883 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_recommendations(index,print_recommendation = False,print_genres =False):\n",
    "  index_recomm =cos_sim_data.loc[index].sort_values(ascending=False).index.tolist()[1:11]\n",
    "  movies_recomm =  data['title'].loc[index_recomm].values\n",
    "  movies_recomm_genres = data['genres'].loc[index_recomm].values\n",
    "  result = {'Movies':movies_recomm,'Index':index_recomm}\n",
    "  if print_recommendation==True:\n",
    "    print('The watched movie is : %s , its generes : %r \\n'%(data['title'].loc[index],data['genres'].loc[index]))\n",
    "    for i in range(len(movies_recomm)):\n",
    "      print('Rank %i recommended movie is : %s , its generes : %r \\n'%(i+1,movies_recomm[i],movies_recomm_genres[i]))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watched movie is : Waiting to Exhale (1995) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 1 recommended movie is : Auntie Mame (1958) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 2 recommended movie is : Slingshot, The (Kådisbellan ) (1993) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 3 recommended movie is : Welcome to the Dollhouse (1995) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 4 recommended movie is : Train of Life (Train De Vie) (1998) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 5 recommended movie is : Where the Money Is (2000) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 6 recommended movie is : Diner (1982) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 7 recommended movie is : 200 Cigarettes (1999) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 8 recommended movie is : Sirens (1994) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 9 recommended movie is : Henry Fool (1997) , its generes : 'Comedy Drama' \n",
      "\n",
      "Rank 10 recommended movie is : Virgin Suicides, The (1999) , its generes : 'Comedy Drama' \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Movies': array(['Auntie Mame (1958)', 'Slingshot, The (Kådisbellan ) (1993)',\n",
       "        'Welcome to the Dollhouse (1995)',\n",
       "        'Train of Life (Train De Vie) (1998)', 'Where the Money Is (2000)',\n",
       "        'Diner (1982)', '200 Cigarettes (1999)', 'Sirens (1994)',\n",
       "        'Henry Fool (1997)', 'Virgin Suicides, The (1999)'], dtype=object),\n",
       " 'Index': [3479, 566, 558, 2934, 3468, 3474, 2435, 533, 1835, 3487]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_recommendations(3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
